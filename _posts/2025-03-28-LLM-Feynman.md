---
layout: post
title: "LLM-FeynmanがMaterials Informatics最大の課題を解決してしまったのか？"
date: 2025-03-28
---

<div align="center">
<img src="/assets/img/20250328_LLM-Feynman/asking_LLM.png" width="50%" alt="LLM-asking">
</div>

この論文を目にして、コロナ騒動が始まった直後に真冬のNYで参加したAI系の国際学会（AAAI）の情景を思い出さずにはいられない。
自然言語処理セッションの約９割を占める中国系の人たちが、米国入国禁止措置のために、急遽リモート発表に変更となり、だだっ広い会場で聴衆３～５人程度と寂しい雰囲気の中、現地でひたすらリモート発表を聞いた時に感じたことを。

この時は、もともと材料系の研究者であった私が初めて参加した自然言語処理系の国際学会であったが、まず驚いたのは、国際学会なのに人種多様性が低いこと。ほとんどが中国の人。

次に感じたことは、近い将来、Materials Informatics（MI）の分野でも、中国の人たちがけん引する世の中になるであろうという確かな予感。

そんな中、LLM-Feynmanという自然言語処理をベースにしたMIフレームワークに関する論文が出されたとの[記事](https://ledge.ai/articles/ai_discovers_physics_formulas_llm_feynman)を見て、あの時の予感は的中なのか！？ と思ったが、はたして・・・

## [LLM-Feynman: Leveraging Large Language Models for Universal Scientific Formula and Theory Discovery](https://arxiv.org/abs/2503.06512)

### どんな論文？

この論文を注目する理由は、単に経験式を導出するのではなく、なるべく理論的に説明可能な形で「高精度な回帰式」を導出してくれる、つまり、外挿予測にも強そうな回帰式を得られる、と謳っているからです。これって、材料研究者にとっては、夢のような話です！

『初めに断っておくと・・・』という書き方をすると、「あ～、予感は外れたのね～～」となってしまうかもしれないが、ちょっと違う。
実際に原文をたどると、この論文はまだプレプリントの段階であり、本文中に書かれているサポートデータも貼られていない不完全なもの。
つまり、私のような第三者は検証することがでないため、書いてあることを只々信じるしかなく、話半分で読んでもらいたい、ということです。

とはいうものの、気になるのは、実際の成果ですよね。

先ず、論文中に書かれている成果を簡単に紹介すると、**『2D材料やペロブスカイト構造の合成可能性の分類』『固体電解質のイオン伝導率や2D材料のGWバンドギャップの予測』** といったタスクにおいて、解釈可能な数式を高精度に生成できた、というものです。

また、『ファインマン物理学講義から得たデータセットを用いた実験』では、データセットにノイズを加えた場合において、従来の記号回帰法である**AI-Feynman**と比較して好成績を収めた、ということです。

---

### ファインマン物理学講義を用いた実験

この論文では、LLM-Feynmanフレームワークの有効性を検証するために、ファインマン物理学講義から得られたデータセットを用いて実験を行っています。

この実験では、

* 100の基本的な公式を「単純なタスク」
* 20のより複雑な公式を「難しいタスク」

として設定し、**LLM-Feynman**と従来の記号回帰法である**AI-Feynman**の性能を比較しています。

実験の結果、ノイズがない場合、**LLM-Feynman**と**AI-Feynman**はどちらも単純なタスクにおいて全ての公式を正しく識別しました。

しかし、データにノイズを加えた場合、**LLM-Feynman**は**AI-Feynman**よりも高い成功率を維持しました。

* 単純なタスクにおいて、**LLM-Feynman**はノイズレベルが10⁻³および10⁻²の場合でも、それぞれ100%と86%の成功率を達成したのに対し、**AI-Feynman**は85%と67%でした。
* 難しいタスクでは、ノイズレベルが10⁻²の場合、**LLM-Feynman**は90%の成功率を維持しましたが、**AI-Feynman**は55%に低下しました。

---

<div align="center">
<img src="/assets/img/20250328_LLM-Feynman/LLM_vs_AI.png" width="50%" alt="LLM-asking">
</div>

90%とか100%といった数字を見ると、『早く試してみたいな～』となりませんか？

### 技術的にはどうなんだ？

LLMの専門家ではないので、Geminiに要約してもらいました。

----

LLM-Feynmanフレームワークは、自動化されたデータ前処理と特徴エンジニアリング、自己評価と反復改良によるLLMベースの[記号回帰](#記号回帰)、[モンテカルロ木探索（MCTS）](#MCTS)による数式解釈の3つの主要モジュールで構成されています 。  

1. 自動データ前処理と特徴エンジニアリング: 入力データの特徴量と目標値の物理的な意味と次元を考慮して、欠損値の処理や特徴量の正規化などの前処理を自動的に行います。材料科学の問題に対しては、特徴量の選択、LLM推奨の特徴量マッチング、反復的な特徴量改良という3つの自動化された特徴量計算スキームを組み込んでいます 。  

2. LLMベースの記号回帰: LLMを活用して数式を生成し、自己評価によって解釈可能性を評価します。そして、多目的最適化を用いて、精度、複雑さ、解釈可能性のバランスを取りながら、最適な数式を探索します 。  

3. 数式解釈: モンテカルロ木探索（MCTS）とLLMを統合することで、数式の物理的・化学的な意味を体系的に解釈し、改良します。MCTSは、LLMが生成した解釈のアイデアを探索木で表現し、各ノードのスコアをUCB（Upper Confidence Bound）に基づいて決定することで、解釈空間を効率的に探索します。

----

なんだか、凄そうですね！

<div align="center">
<img src="/assets/img/20250328_LLM-Feynman/Monte_Carlo_tree.png" width="50%" alt="LLM-asking">
</div>

### 独自の見解

私の研究者生活を振り返ると、常に経験式との戦いでした。
実験データから材料の特性を予測する経験式を導くことは、材料開発において避けて通れない重要なプロセスですが、多くの時間と労力を要する作業でもありました。
もし、LLM-Feynmanのようなツールがあれば、このプロセスが大幅に効率化され、より迅速に材料開発を進められるのではないかと期待しています。

さらに、これまで個々の研究テーマが終了する度に、そこで得られた経験式は、その場限りの知識として埋もれてしまい、十分に活用されているとは言えない状況でした。
しかし、LLM-Feynmanが、これらの経験式を蓄積し、発展させることを可能にするのであれば、過去の知見を未来の材料開発に活かすことができ、材料開発をさらに加速させることができるかもしれません。

また、企業には長年の研究開発によって蓄積された膨大な量の実験データやノウハウが存在しますが、それらは必ずしも組織全体で共有・活用されているとは限りません。
LLM-Feynmanが、これらの社内に散在する経験・知識を統合し、新たな知見を生み出す力を持つのであれば、材料開発における企業の競争力を大きく向上させる可能性を秘めていると感じています。

### 今後の展望

この研究がさらに発展すれば、材料開発の現場は大きく変わる可能性があります。
LLM-Feynmanが、研究者の直感や経験に頼っていた部分をAIによって補完し、新たな材料開発の可能性を広げてくれるかもしれません。

今後の研究の進展に、大いに期待したいと思います。

----
脚注

1. 記号回帰 (Symbolic Regression)<a id="記号回帰"></a>: 数式を自動的に発見する技術のことです。与えられたデータに対して、最もよく当てはまる数式を、コンピューターが様々な組み合わせを試しながら探します。


2. モンテカルロ木探索 (Monte Carlo Tree Search, MCTS)<a id="MCTS"></a>: ゲームAIなどでよく使われる探索アルゴリズムの一種で、試行錯誤を繰り返しながら、最適な選択肢を見つけ出すための手法です。この論文では、LLMが生成した数式の解釈を効率的に探索するために用いられています。
